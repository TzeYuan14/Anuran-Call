{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3c3f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "%config Completer.use_jedi = False\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "410036a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_14</th>\n",
       "      <th>MFCCs_15</th>\n",
       "      <th>MFCCs_16</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6563</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.511578</td>\n",
       "      <td>0.500568</td>\n",
       "      <td>0.289810</td>\n",
       "      <td>0.028352</td>\n",
       "      <td>0.152389</td>\n",
       "      <td>0.091804</td>\n",
       "      <td>-0.073538</td>\n",
       "      <td>0.079625</td>\n",
       "      <td>0.075513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029002</td>\n",
       "      <td>-0.001082</td>\n",
       "      <td>0.069663</td>\n",
       "      <td>-0.033013</td>\n",
       "      <td>-0.043957</td>\n",
       "      <td>0.027965</td>\n",
       "      <td>-0.044238</td>\n",
       "      <td>-0.052566</td>\n",
       "      <td>0.073165</td>\n",
       "      <td>HypsiboasCordobae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.210061</td>\n",
       "      <td>0.132931</td>\n",
       "      <td>0.527246</td>\n",
       "      <td>0.184801</td>\n",
       "      <td>0.016609</td>\n",
       "      <td>-0.166408</td>\n",
       "      <td>-0.032586</td>\n",
       "      <td>0.298333</td>\n",
       "      <td>0.062479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082268</td>\n",
       "      <td>-0.269823</td>\n",
       "      <td>0.083616</td>\n",
       "      <td>0.230827</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>-0.152588</td>\n",
       "      <td>-0.152686</td>\n",
       "      <td>0.054161</td>\n",
       "      <td>0.234673</td>\n",
       "      <td>AdenomeraHylaedactylus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.439234</td>\n",
       "      <td>0.180046</td>\n",
       "      <td>0.513669</td>\n",
       "      <td>0.071863</td>\n",
       "      <td>0.033051</td>\n",
       "      <td>-0.096263</td>\n",
       "      <td>-0.073786</td>\n",
       "      <td>0.202717</td>\n",
       "      <td>0.016256</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156668</td>\n",
       "      <td>-0.183860</td>\n",
       "      <td>0.128085</td>\n",
       "      <td>0.113693</td>\n",
       "      <td>-0.032615</td>\n",
       "      <td>-0.074054</td>\n",
       "      <td>-0.116183</td>\n",
       "      <td>0.065055</td>\n",
       "      <td>0.179867</td>\n",
       "      <td>AdenomeraHylaedactylus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5682</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.493535</td>\n",
       "      <td>0.423131</td>\n",
       "      <td>0.247821</td>\n",
       "      <td>0.027608</td>\n",
       "      <td>0.150273</td>\n",
       "      <td>0.059945</td>\n",
       "      <td>-0.051361</td>\n",
       "      <td>0.085261</td>\n",
       "      <td>0.108716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>-0.090093</td>\n",
       "      <td>0.018968</td>\n",
       "      <td>0.065716</td>\n",
       "      <td>-0.011326</td>\n",
       "      <td>-0.001308</td>\n",
       "      <td>0.025194</td>\n",
       "      <td>-0.015544</td>\n",
       "      <td>0.025955</td>\n",
       "      <td>HypsiboasCordobae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6095</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068448</td>\n",
       "      <td>0.294904</td>\n",
       "      <td>0.402516</td>\n",
       "      <td>0.227617</td>\n",
       "      <td>0.222653</td>\n",
       "      <td>0.110672</td>\n",
       "      <td>-0.175465</td>\n",
       "      <td>-0.079616</td>\n",
       "      <td>0.095423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020731</td>\n",
       "      <td>-0.120213</td>\n",
       "      <td>-0.017857</td>\n",
       "      <td>0.100556</td>\n",
       "      <td>0.057638</td>\n",
       "      <td>-0.003940</td>\n",
       "      <td>-0.022400</td>\n",
       "      <td>-0.073098</td>\n",
       "      <td>-0.027459</td>\n",
       "      <td>HypsiboasCordobae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011335</td>\n",
       "      <td>-0.124341</td>\n",
       "      <td>0.296202</td>\n",
       "      <td>0.122151</td>\n",
       "      <td>0.074736</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>0.052122</td>\n",
       "      <td>0.262498</td>\n",
       "      <td>0.167792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045425</td>\n",
       "      <td>-0.276949</td>\n",
       "      <td>0.007776</td>\n",
       "      <td>0.199462</td>\n",
       "      <td>0.086548</td>\n",
       "      <td>-0.122710</td>\n",
       "      <td>-0.186576</td>\n",
       "      <td>0.002982</td>\n",
       "      <td>0.235526</td>\n",
       "      <td>AdenomeraHylaedactylus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>0.590645</td>\n",
       "      <td>0.955701</td>\n",
       "      <td>0.418602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.107920</td>\n",
       "      <td>-0.009094</td>\n",
       "      <td>-0.235536</td>\n",
       "      <td>0.186496</td>\n",
       "      <td>0.412626</td>\n",
       "      <td>-0.314135</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.200425</td>\n",
       "      <td>-0.412393</td>\n",
       "      <td>0.288542</td>\n",
       "      <td>0.319573</td>\n",
       "      <td>-0.053652</td>\n",
       "      <td>-0.113245</td>\n",
       "      <td>-0.326972</td>\n",
       "      <td>0.096694</td>\n",
       "      <td>0.209796</td>\n",
       "      <td>AdenomeraHylaedactylus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6674</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.324977</td>\n",
       "      <td>0.583659</td>\n",
       "      <td>-0.011086</td>\n",
       "      <td>0.025217</td>\n",
       "      <td>0.324029</td>\n",
       "      <td>0.055629</td>\n",
       "      <td>-0.125459</td>\n",
       "      <td>-0.024524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118563</td>\n",
       "      <td>-0.382332</td>\n",
       "      <td>-0.142126</td>\n",
       "      <td>0.204189</td>\n",
       "      <td>-0.033678</td>\n",
       "      <td>-0.199777</td>\n",
       "      <td>0.084925</td>\n",
       "      <td>0.148482</td>\n",
       "      <td>-0.127293</td>\n",
       "      <td>LeptodactylusFuscus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.264015</td>\n",
       "      <td>0.103518</td>\n",
       "      <td>0.558752</td>\n",
       "      <td>0.237474</td>\n",
       "      <td>0.133820</td>\n",
       "      <td>-0.141718</td>\n",
       "      <td>-0.040560</td>\n",
       "      <td>0.200562</td>\n",
       "      <td>0.064745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049337</td>\n",
       "      <td>-0.287562</td>\n",
       "      <td>0.019555</td>\n",
       "      <td>0.236875</td>\n",
       "      <td>0.071364</td>\n",
       "      <td>-0.078546</td>\n",
       "      <td>-0.174420</td>\n",
       "      <td>-0.029079</td>\n",
       "      <td>0.225232</td>\n",
       "      <td>AdenomeraHylaedactylus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6659</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.505665</td>\n",
       "      <td>0.754755</td>\n",
       "      <td>0.170904</td>\n",
       "      <td>-0.143673</td>\n",
       "      <td>0.317503</td>\n",
       "      <td>0.115409</td>\n",
       "      <td>-0.149176</td>\n",
       "      <td>0.118609</td>\n",
       "      <td>0.175379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033836</td>\n",
       "      <td>-0.064877</td>\n",
       "      <td>0.068252</td>\n",
       "      <td>0.080136</td>\n",
       "      <td>-0.055742</td>\n",
       "      <td>-0.013665</td>\n",
       "      <td>0.034822</td>\n",
       "      <td>-0.032049</td>\n",
       "      <td>-0.070829</td>\n",
       "      <td>LeptodactylusFuscus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "6563  1.000000  0.511578  0.500568  0.289810  0.028352  0.152389  0.091804   \n",
       "1521  1.000000  0.210061  0.132931  0.527246  0.184801  0.016609 -0.166408   \n",
       "3975  1.000000  0.439234  0.180046  0.513669  0.071863  0.033051 -0.096263   \n",
       "5682  1.000000  0.493535  0.423131  0.247821  0.027608  0.150273  0.059945   \n",
       "6095  1.000000  0.068448  0.294904  0.402516  0.227617  0.222653  0.110672   \n",
       "3401  1.000000  0.011335 -0.124341  0.296202  0.122151  0.074736  0.006696   \n",
       "2435  0.590645  0.955701  0.418602  1.000000  0.107920 -0.009094 -0.235536   \n",
       "6674  1.000000  0.088428  0.324977  0.583659 -0.011086  0.025217  0.324029   \n",
       "1706  1.000000  0.264015  0.103518  0.558752  0.237474  0.133820 -0.141718   \n",
       "6659  1.000000  0.505665  0.754755  0.170904 -0.143673  0.317503  0.115409   \n",
       "\n",
       "      MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_14  MFCCs_15  MFCCs_16  \\\n",
       "6563 -0.073538  0.079625  0.075513  ... -0.029002 -0.001082  0.069663   \n",
       "1521 -0.032586  0.298333  0.062479  ... -0.082268 -0.269823  0.083616   \n",
       "3975 -0.073786  0.202717  0.016256  ... -0.156668 -0.183860  0.128085   \n",
       "5682 -0.051361  0.085261  0.108716  ...  0.006241 -0.090093  0.018968   \n",
       "6095 -0.175465 -0.079616  0.095423  ... -0.020731 -0.120213 -0.017857   \n",
       "3401  0.052122  0.262498  0.167792  ... -0.045425 -0.276949  0.007776   \n",
       "2435  0.186496  0.412626 -0.314135  ... -0.200425 -0.412393  0.288542   \n",
       "6674  0.055629 -0.125459 -0.024524  ...  0.118563 -0.382332 -0.142126   \n",
       "1706 -0.040560  0.200562  0.064745  ... -0.049337 -0.287562  0.019555   \n",
       "6659 -0.149176  0.118609  0.175379  ...  0.033836 -0.064877  0.068252   \n",
       "\n",
       "      MFCCs_17  MFCCs_18  MFCCs_19  MFCCs_20  MFCCs_21  MFCCs_22  \\\n",
       "6563 -0.033013 -0.043957  0.027965 -0.044238 -0.052566  0.073165   \n",
       "1521  0.230827 -0.000121 -0.152588 -0.152686  0.054161  0.234673   \n",
       "3975  0.113693 -0.032615 -0.074054 -0.116183  0.065055  0.179867   \n",
       "5682  0.065716 -0.011326 -0.001308  0.025194 -0.015544  0.025955   \n",
       "6095  0.100556  0.057638 -0.003940 -0.022400 -0.073098 -0.027459   \n",
       "3401  0.199462  0.086548 -0.122710 -0.186576  0.002982  0.235526   \n",
       "2435  0.319573 -0.053652 -0.113245 -0.326972  0.096694  0.209796   \n",
       "6674  0.204189 -0.033678 -0.199777  0.084925  0.148482 -0.127293   \n",
       "1706  0.236875  0.071364 -0.078546 -0.174420 -0.029079  0.225232   \n",
       "6659  0.080136 -0.055742 -0.013665  0.034822 -0.032049 -0.070829   \n",
       "\n",
       "                     Species  \n",
       "6563       HypsiboasCordobae  \n",
       "1521  AdenomeraHylaedactylus  \n",
       "3975  AdenomeraHylaedactylus  \n",
       "5682       HypsiboasCordobae  \n",
       "6095       HypsiboasCordobae  \n",
       "3401  AdenomeraHylaedactylus  \n",
       "2435  AdenomeraHylaedactylus  \n",
       "6674     LeptodactylusFuscus  \n",
       "1706  AdenomeraHylaedactylus  \n",
       "6659     LeptodactylusFuscus  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file and store into dataFrame\n",
    "anuran = pd.read_csv('frogs_mfcc.csv', sep = ',')\n",
    "anuran.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1934db84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7195, 22)\n",
      "(7195,)\n"
     ]
    }
   ],
   "source": [
    "############################################################################\n",
    "#                          Split the dataset\n",
    "############################################################################\n",
    "\n",
    "seed_num = 0\n",
    "\n",
    "# Seperate the data into dependent and independent variables\n",
    "X = anuran.drop(['Species'], axis = 1)\n",
    "y = anuran['Species'].values\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Scale or normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Divide the dataset: 80% for training set and 20% for test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87dd1b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "#                  Convert categorical data into numerical\n",
    "############################################################################\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Convert categorical data (y_train) into integer data\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Convert integer data into binary class matrix\n",
    "y_train_encoded = to_categorical(integer_encoded)\n",
    "\n",
    "# Convert categorical data (y_test) into integer data\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e482702",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "#                       Construct a neural network\n",
    "############################################################################\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "l2 = l2(l=0.01)      # Specify the weight of the regularization\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(22,)),\n",
    "    Dense(50, activation='relu', dtype='float64', kernel_regularizer='l2'), # Apply l2\n",
    "    Dropout(0.25),\n",
    "    BatchNormalization(),\n",
    "    Dense(10, activation='sigmoid', dtype='float64', kernel_regularizer='l2')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47693a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                1150      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 50)               200       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,860\n",
      "Trainable params: 1,760\n",
      "Non-trainable params: 100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc5a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()  # For multi-class classification\n",
    "\n",
    "model.compile(optimizer='adam',       # optimizer used to train the model\n",
    "              loss=loss_fn,           # loss function is specified\n",
    "              metrics=['accuracy'])   # metric used to monitor the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e68aaab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "180/180 [==============================] - 1s 2ms/step - loss: 1.6755 - accuracy: 0.6223\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.8727 - accuracy: 0.8570\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.8860\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.9048\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.9138\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.9177\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.9248\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.9267\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.9333\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.9338\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.9298\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.3990 - accuracy: 0.9375\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.9395\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.9432\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.3654 - accuracy: 0.9432\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.3556 - accuracy: 0.9453\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.3549 - accuracy: 0.9461\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.3497 - accuracy: 0.9465\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.9442\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.9486\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.9493\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.9463\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.9477\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.9486\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.9503\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.9475\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.9529\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.3062 - accuracy: 0.9482\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.2965 - accuracy: 0.9536\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.2959 - accuracy: 0.9507\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.3051 - accuracy: 0.9486\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.2927 - accuracy: 0.9515\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.9529\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2926 - accuracy: 0.9486\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.9524\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2853 - accuracy: 0.9521\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2865 - accuracy: 0.9507\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2897 - accuracy: 0.9498\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2815 - accuracy: 0.9501\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.2792 - accuracy: 0.9529\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.2775 - accuracy: 0.9547\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.2686 - accuracy: 0.9548\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.2660 - accuracy: 0.9543\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.2674 - accuracy: 0.9541\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.2573 - accuracy: 0.9585\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.2607 - accuracy: 0.9588\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2687 - accuracy: 0.9517\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.9552\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2542 - accuracy: 0.9573\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.9545\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.9548\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.9545\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 0.9538\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.9552\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.9593\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.2429 - accuracy: 0.9581\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.2513 - accuracy: 0.9560\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.2563 - accuracy: 0.9545\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 1s 3ms/step - loss: 0.2634 - accuracy: 0.9547\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2589 - accuracy: 0.9526\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 2ms/step - loss: 0.2557 - accuracy: 0.9507\n"
     ]
    }
   ],
   "source": [
    "############################################################################\n",
    "#                     Implement early stopping regularization\n",
    "############################################################################\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "my_callbacks = [\n",
    "    EarlyStopping(patience=5, monitor='loss')\n",
    "]\n",
    "\n",
    "history = model.fit(X_train, y_train_encoded, batch_size=32, epochs=100, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c17d4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ec37424c40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "loss_train = history.history['loss']\n",
    "\n",
    "plt.plot(loss_train, label='train loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "487c8c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 4ms/step\n",
      "Accuracy: 0.9610840861709521\n",
      " \n",
      "Confusion matrix:\n",
      "[[129   0   6   1   0   1   0   2   0   0]\n",
      " [  0 695   0   0   1   0   0   0   0   0]\n",
      " [  1   0  94   0   0   0   0   0   0   0]\n",
      " [  8  11   7  38   0   1   0   0   0   3]\n",
      " [  0   0   0   0  98   0   0   0   0   0]\n",
      " [  0   2   0   0   1 220   1   2   0   0]\n",
      " [  0   0   0   1   0   1  50   1   0   0]\n",
      " [  0   0   0   0   4   0   0  16   0   0]\n",
      " [  0   0   0   0   0   0   0   0  12   1]\n",
      " [  0   0   0   0   0   0   0   0   0  31]]\n",
      " \n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       139\n",
      "           1       0.98      1.00      0.99       696\n",
      "           2       0.88      0.99      0.93        95\n",
      "           3       0.95      0.56      0.70        68\n",
      "           4       0.94      1.00      0.97        98\n",
      "           5       0.99      0.97      0.98       226\n",
      "           6       0.98      0.94      0.96        53\n",
      "           7       0.76      0.80      0.78        20\n",
      "           8       1.00      0.92      0.96        13\n",
      "           9       0.89      1.00      0.94        31\n",
      "\n",
      "    accuracy                           0.96      1439\n",
      "   macro avg       0.93      0.91      0.91      1439\n",
      "weighted avg       0.96      0.96      0.96      1439\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)     # Convert into integer data\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test_encoded, y_pred))\n",
    "print(\" \")\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(y_test_encoded, y_pred))\n",
    "print(\" \")\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test_encoded, y_pred))\n",
    "print(\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
